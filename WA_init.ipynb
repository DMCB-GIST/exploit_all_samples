{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60f0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as fs\n",
    "import pyarrow\n",
    "import datasets\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22509d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hyperparameters\n"
     ]
    }
   ],
   "source": [
    "print('Training hyperparameters')\n",
    "##################################################\n",
    "use_rate = 0.02 # to implement low-resource settings\n",
    "si = 7 # sample seed \n",
    "lr = 2e-5 # learning rate\n",
    "dr = 0.1 # drop out\n",
    "btchs = 32 # batch size\n",
    "epochs = 70 # training epochs\n",
    "max_length = 64 # sentence length\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8a319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load\n",
      "Experimental data: SST-binary.\n",
      "# of original labeled data: 7792.\n",
      "# of labeled data for low-resource settings: 156.\n",
      "# of test data: 1821.\n"
     ]
    }
   ],
   "source": [
    "print('Data load')\n",
    "##################################################\n",
    "data = 'SST-binary'\n",
    "data_trn_path = f'./data/{data}/{data}.train.evenly.shuffled.txt'\n",
    "data_tst_path = f'./data/{data}/{data}.test.not.shuffled.txt'\n",
    "label_list = ['0','1']\n",
    "##################################################\n",
    "\n",
    "label_map = {l:i for i,l in enumerate(label_list)}\n",
    "num_labels = len(label_list)\n",
    "\n",
    "samples = fs.text_reader(data_trn_path)\n",
    "examples = fs.samples2examples(samples)\n",
    "tst_samples = fs.text_reader(data_tst_path)\n",
    "tst_examples = fs.samples2examples(tst_samples) \n",
    "\n",
    "print(f'Experimental data: {data}.')\n",
    "print(f'# of original labeled data: {len(samples)}.')\n",
    "print(f'# of labeled data for low-resource settings: {int(use_rate*len(samples)+0.5)}.')\n",
    "print(f'# of test data: {len(tst_samples)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335b71a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: bert-base-uncased.\n",
      "GPU No.: 2.\n"
     ]
    }
   ],
   "source": [
    "print('Model load')\n",
    "##################################################\n",
    "pt_model = \"bert-base-uncased\"\n",
    "gpu = '2'\n",
    "##################################################\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") \n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "tokenizer = AutoTokenizer.from_pretrained(pt_model)\n",
    "\n",
    "model = AutoModel.from_pretrained(pt_model)\n",
    "init_state_dict = model.state_dict()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(f'Model name: {pt_model}.')\n",
    "print(f'GPU No.: {gpu}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e04c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter-set generation\n",
      "Saved the dense_wbs_set at Wed Jun 21 16:01:51 2023.\n",
      "# of features at the final layer: 768.\n",
      "# of param_sets: 5.\n"
     ]
    }
   ],
   "source": [
    "print('Parameter-set generation')\n",
    "##################################################\n",
    "n_base = 5 # number of training repetitions\n",
    "##################################################\n",
    "\n",
    "num_features = model.pooler.dense.out_features\n",
    "\n",
    "if not os.path.exists(f'./params/dense_wbs_set_si{si}.bin'):\n",
    "    dense_wbs_set = []\n",
    "    for base_i in range(n_base):\n",
    "        dense_layer = nn.Linear(num_features, len(label_list))\n",
    "        dense_w = list( dense_layer.parameters() )[0].detach().numpy() \n",
    "        dense_b = list( dense_layer.parameters() )[1].detach().numpy() \n",
    "        dense_wbs_set.append((dense_w,dense_b))\n",
    "    fs.dump_all(dense_wbs_set, f'./params/dense_wbs_set_si{si}.bin')\n",
    "    print(f'Saved the dense_wbs_set at {time.ctime()}.')\n",
    "else:\n",
    "    dense_wbs_set = fs.load_all(f'./params/dense_wbs_set_si{si}.bin')\n",
    "    print(f'Load the dense_wbs_set.')\n",
    "\n",
    "print(f'# of features at the final layer: {num_features}.')\n",
    "print(f'# of param_sets: {len(dense_wbs_set)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1b7bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate a trn-conf criterion.\n",
      "##################################################\n",
      "si=7\n",
      "■ ki=0/4 (si=7)\n",
      "■■ base_i=0/5 (si=7, ki=0/4)\n",
      "■■■ epoch=1, val_acc=0.4359, val_loss=0.7079  #\n",
      "■■■ epoch=2, val_acc=0.5641, val_loss=0.6973  #\n",
      "■■■ epoch=3, val_acc=0.5897, val_loss=0.6814  #\n",
      "■■■ epoch=4, val_acc=0.6154, val_loss=0.6509  #\n",
      "■■■ epoch=5, val_acc=0.6667, val_loss=0.6509 \n",
      "■■■ epoch=6, val_acc=0.641, val_loss=0.6919 \n",
      "■■■ epoch=7, val_acc=0.6923, val_loss=0.6227  #\n",
      "■■■ epoch=8, val_acc=0.7179, val_loss=0.5788  #\n",
      "■■■ epoch=9, val_acc=0.6667, val_loss=0.6772 \n",
      "■■■ epoch=10, val_acc=0.6667, val_loss=0.7431 \n",
      "■■■ epoch=11, val_acc=0.6923, val_loss=0.7426 \n",
      "■■■ epoch=12, val_acc=0.7179, val_loss=0.7222 \n",
      "■■■ epoch=13, val_acc=0.7436, val_loss=0.7264 \n",
      "■■■ epoch=14, val_acc=0.7436, val_loss=0.7395 \n",
      "■■■ epoch=15, val_acc=0.7692, val_loss=0.7232 \n",
      "■■■ epoch=16, val_acc=0.7692, val_loss=0.7314 \n",
      "■■■ epoch=17, val_acc=0.7692, val_loss=0.7579 \n",
      "■■■ epoch=18, val_acc=0.7692, val_loss=0.794 \n",
      "■■ base_i=1/5 (si=7, ki=0/4)\n",
      "■■■ epoch=1, val_acc=0.5897, val_loss=0.679 \n",
      "■■■ epoch=2, val_acc=0.7436, val_loss=0.6699 \n",
      "■■■ epoch=3, val_acc=0.7436, val_loss=0.6526 \n",
      "■■■ epoch=4, val_acc=0.5897, val_loss=0.622 \n",
      "■■■ epoch=5, val_acc=0.5897, val_loss=0.6 \n",
      "■■■ epoch=6, val_acc=0.7692, val_loss=0.5435  #\n",
      "■■■ epoch=7, val_acc=0.7692, val_loss=0.5059  #\n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.5207 \n",
      "■■■ epoch=9, val_acc=0.8205, val_loss=0.4658  #\n",
      "■■■ epoch=10, val_acc=0.7949, val_loss=0.4321  #\n",
      "■■■ epoch=11, val_acc=0.8462, val_loss=0.4465 \n",
      "■■■ epoch=12, val_acc=0.8462, val_loss=0.4869 \n",
      "■■■ epoch=13, val_acc=0.8205, val_loss=0.5449 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.6095 \n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.6649 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.7125 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.7564 \n",
      "■■■ epoch=18, val_acc=0.8205, val_loss=0.7954 \n",
      "■■■ epoch=19, val_acc=0.8205, val_loss=0.8276 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.8565 \n",
      "■■ base_i=2/5 (si=7, ki=0/4)\n",
      "■■■ epoch=1, val_acc=0.4615, val_loss=0.7003 \n",
      "■■■ epoch=2, val_acc=0.5128, val_loss=0.6885 \n",
      "■■■ epoch=3, val_acc=0.641, val_loss=0.6782 \n",
      "■■■ epoch=4, val_acc=0.6154, val_loss=0.6708 \n",
      "■■■ epoch=5, val_acc=0.6923, val_loss=0.6468 \n",
      "■■■ epoch=6, val_acc=0.641, val_loss=0.6273 \n",
      "■■■ epoch=7, val_acc=0.7179, val_loss=0.6083 \n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.5859 \n",
      "■■■ epoch=9, val_acc=0.7436, val_loss=0.5768 \n",
      "■■■ epoch=10, val_acc=0.7692, val_loss=0.5674 \n",
      "■■■ epoch=11, val_acc=0.7949, val_loss=0.5632 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.5647 \n",
      "■■■ epoch=13, val_acc=0.7949, val_loss=0.5758 \n",
      "■■■ epoch=14, val_acc=0.7949, val_loss=0.5919 \n",
      "■■■ epoch=15, val_acc=0.7949, val_loss=0.6115 \n",
      "■■■ epoch=16, val_acc=0.7949, val_loss=0.6365 \n",
      "■■■ epoch=17, val_acc=0.7949, val_loss=0.6652 \n",
      "■■■ epoch=18, val_acc=0.7949, val_loss=0.6962 \n",
      "■■■ epoch=19, val_acc=0.7949, val_loss=0.7271 \n",
      "■■■ epoch=20, val_acc=0.7949, val_loss=0.755 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.7804 \n",
      "■■ base_i=3/5 (si=7, ki=0/4)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.6693 \n",
      "■■■ epoch=2, val_acc=0.5897, val_loss=0.6542 \n",
      "■■■ epoch=3, val_acc=0.641, val_loss=0.6406 \n",
      "■■■ epoch=4, val_acc=0.6923, val_loss=0.6222 \n",
      "■■■ epoch=5, val_acc=0.7179, val_loss=0.5877 \n",
      "■■■ epoch=6, val_acc=0.7179, val_loss=0.5967 \n",
      "■■■ epoch=7, val_acc=0.7436, val_loss=0.5333 \n",
      "■■■ epoch=8, val_acc=0.7692, val_loss=0.5077 \n",
      "■■■ epoch=9, val_acc=0.8205, val_loss=0.5259 \n",
      "■■■ epoch=10, val_acc=0.8205, val_loss=0.51 \n",
      "■■■ epoch=11, val_acc=0.7692, val_loss=0.5008 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.5123 \n",
      "■■■ epoch=13, val_acc=0.7949, val_loss=0.5265 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.5468 \n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.5626 \n",
      "■■■ epoch=16, val_acc=0.8462, val_loss=0.5768 \n",
      "■■■ epoch=17, val_acc=0.8462, val_loss=0.5942 \n",
      "■■■ epoch=18, val_acc=0.8205, val_loss=0.6159 \n",
      "■■■ epoch=19, val_acc=0.8205, val_loss=0.6381 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.6568 \n",
      "■■■ epoch=21, val_acc=0.8205, val_loss=0.6714 \n",
      "■■ base_i=4/5 (si=7, ki=0/4)\n",
      "■■■ epoch=1, val_acc=0.5128, val_loss=0.6807 \n",
      "■■■ epoch=2, val_acc=0.6667, val_loss=0.6725 \n",
      "■■■ epoch=3, val_acc=0.641, val_loss=0.6581 \n",
      "■■■ epoch=4, val_acc=0.5385, val_loss=0.6583 \n",
      "■■■ epoch=5, val_acc=0.641, val_loss=0.6316 \n",
      "■■■ epoch=6, val_acc=0.6667, val_loss=0.6069 \n",
      "■■■ epoch=7, val_acc=0.6667, val_loss=0.5986 \n",
      "■■■ epoch=8, val_acc=0.641, val_loss=0.5815 \n",
      "■■■ epoch=9, val_acc=0.7436, val_loss=0.5464 \n",
      "■■■ epoch=10, val_acc=0.6667, val_loss=0.5691 \n",
      "■■■ epoch=11, val_acc=0.6667, val_loss=0.6113 \n",
      "■■■ epoch=12, val_acc=0.7436, val_loss=0.606 \n",
      "■■■ epoch=13, val_acc=0.7436, val_loss=0.6166 \n",
      "■■■ epoch=14, val_acc=0.7692, val_loss=0.6404 \n",
      "■■■ epoch=15, val_acc=0.7436, val_loss=0.6949 \n",
      "■■■ epoch=16, val_acc=0.7436, val_loss=0.7408 \n",
      "■■■ epoch=17, val_acc=0.7692, val_loss=0.7606 \n",
      "■■■ epoch=18, val_acc=0.7692, val_loss=0.7722 \n",
      "■■■ epoch=19, val_acc=0.7692, val_loss=0.7793 \n",
      "■ ki=1/4 (si=7)\n",
      "■■ base_i=0/5 (si=7, ki=1/4)\n",
      "■■■ epoch=1, val_acc=0.4359, val_loss=0.7252  #\n",
      "■■■ epoch=2, val_acc=0.5385, val_loss=0.7024  #\n",
      "■■■ epoch=3, val_acc=0.6154, val_loss=0.6591  #\n",
      "■■■ epoch=4, val_acc=0.7436, val_loss=0.5964  #\n",
      "■■■ epoch=5, val_acc=0.6667, val_loss=0.5531  #\n",
      "■■■ epoch=6, val_acc=0.6923, val_loss=0.5598 \n",
      "■■■ epoch=7, val_acc=0.7692, val_loss=0.4897  #\n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.4921 \n",
      "■■■ epoch=9, val_acc=0.7692, val_loss=0.5086 \n",
      "■■■ epoch=10, val_acc=0.7179, val_loss=0.5985 \n",
      "■■■ epoch=11, val_acc=0.7436, val_loss=0.5889 \n",
      "■■■ epoch=12, val_acc=0.7692, val_loss=0.5272 \n",
      "■■■ epoch=13, val_acc=0.8205, val_loss=0.4801  #\n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.4723  #\n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.4764 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.4752 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.4789 \n",
      "■■■ epoch=18, val_acc=0.7949, val_loss=0.4791 \n",
      "■■■ epoch=19, val_acc=0.7949, val_loss=0.4828 \n",
      "■■■ epoch=20, val_acc=0.7949, val_loss=0.4849 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.4876 \n",
      "■■■ epoch=22, val_acc=0.7949, val_loss=0.4916 \n",
      "■■■ epoch=23, val_acc=0.8205, val_loss=0.4967 \n",
      "■■■ epoch=24, val_acc=0.8205, val_loss=0.5027 \n",
      "■■ base_i=1/5 (si=7, ki=1/4)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.6871 \n",
      "■■■ epoch=2, val_acc=0.641, val_loss=0.6705 \n",
      "■■■ epoch=3, val_acc=0.4359, val_loss=0.6609 \n",
      "■■■ epoch=4, val_acc=0.5641, val_loss=0.6387 \n",
      "■■■ epoch=5, val_acc=0.6667, val_loss=0.5884 \n",
      "■■■ epoch=6, val_acc=0.8718, val_loss=0.5229 \n",
      "■■■ epoch=7, val_acc=0.8462, val_loss=0.4578  #\n",
      "■■■ epoch=8, val_acc=0.8462, val_loss=0.4028  #\n",
      "■■■ epoch=9, val_acc=0.8462, val_loss=0.3551  #\n",
      "■■■ epoch=10, val_acc=0.8718, val_loss=0.3219  #\n",
      "■■■ epoch=11, val_acc=0.8718, val_loss=0.3122  #\n",
      "■■■ epoch=12, val_acc=0.8718, val_loss=0.3281 \n",
      "■■■ epoch=13, val_acc=0.8718, val_loss=0.343 \n",
      "■■■ epoch=14, val_acc=0.8718, val_loss=0.3582 \n",
      "■■■ epoch=15, val_acc=0.8462, val_loss=0.3748 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.3888 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.3985 \n",
      "■■■ epoch=18, val_acc=0.8462, val_loss=0.4054 \n",
      "■■■ epoch=19, val_acc=0.8462, val_loss=0.4117 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.4188 \n",
      "■■■ epoch=21, val_acc=0.8205, val_loss=0.4277 \n",
      "■■ base_i=2/5 (si=7, ki=1/4)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.708 \n",
      "■■■ epoch=2, val_acc=0.4615, val_loss=0.6921 \n",
      "■■■ epoch=3, val_acc=0.5385, val_loss=0.6958 \n",
      "■■■ epoch=4, val_acc=0.5128, val_loss=0.6847 \n",
      "■■■ epoch=5, val_acc=0.5641, val_loss=0.691 \n",
      "■■■ epoch=6, val_acc=0.5128, val_loss=0.7004 \n",
      "■■■ epoch=7, val_acc=0.6154, val_loss=0.7031 \n",
      "■■■ epoch=8, val_acc=0.641, val_loss=0.7179 \n",
      "■■■ epoch=9, val_acc=0.6667, val_loss=0.7125 \n",
      "■■■ epoch=10, val_acc=0.6923, val_loss=0.7051 \n",
      "■■■ epoch=11, val_acc=0.6667, val_loss=0.7022 \n",
      "■■■ epoch=12, val_acc=0.6667, val_loss=0.7079 \n",
      "■■■ epoch=13, val_acc=0.6923, val_loss=0.6777 \n",
      "■■■ epoch=14, val_acc=0.6923, val_loss=0.6485 \n",
      "■■■ epoch=15, val_acc=0.6923, val_loss=0.6527 \n",
      "■■■ epoch=16, val_acc=0.6923, val_loss=0.6689 \n",
      "■■■ epoch=17, val_acc=0.6923, val_loss=0.6956 \n",
      "■■■ epoch=18, val_acc=0.7179, val_loss=0.7337 \n",
      "■■■ epoch=19, val_acc=0.6923, val_loss=0.7774 \n",
      "■■■ epoch=20, val_acc=0.6923, val_loss=0.8157 \n",
      "■■■ epoch=21, val_acc=0.6667, val_loss=0.8421 \n",
      "■■■ epoch=22, val_acc=0.6923, val_loss=0.8564 \n",
      "■■■ epoch=23, val_acc=0.6923, val_loss=0.8673 \n",
      "■■■ epoch=24, val_acc=0.6923, val_loss=0.874 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■ base_i=3/5 (si=7, ki=1/4)\n",
      "■■■ epoch=1, val_acc=0.4872, val_loss=0.6769 \n",
      "■■■ epoch=2, val_acc=0.6154, val_loss=0.6628 \n",
      "■■■ epoch=3, val_acc=0.5897, val_loss=0.6356 \n",
      "■■■ epoch=4, val_acc=0.6667, val_loss=0.613 \n",
      "■■■ epoch=5, val_acc=0.7179, val_loss=0.5732 \n",
      "■■■ epoch=6, val_acc=0.7436, val_loss=0.5509 \n",
      "■■■ epoch=7, val_acc=0.7692, val_loss=0.5045 \n",
      "■■■ epoch=8, val_acc=0.8205, val_loss=0.4796 \n",
      "■■■ epoch=9, val_acc=0.7949, val_loss=0.478 \n",
      "■■■ epoch=10, val_acc=0.8462, val_loss=0.4444 \n",
      "■■■ epoch=11, val_acc=0.8462, val_loss=0.4308 \n",
      "■■■ epoch=12, val_acc=0.8205, val_loss=0.4229 \n",
      "■■■ epoch=13, val_acc=0.8718, val_loss=0.41 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.4238 \n",
      "■■■ epoch=15, val_acc=0.7949, val_loss=0.5107 \n",
      "■■■ epoch=16, val_acc=0.7692, val_loss=0.6167 \n",
      "■■■ epoch=17, val_acc=0.7692, val_loss=0.6424 \n",
      "■■■ epoch=18, val_acc=0.7949, val_loss=0.6506 \n",
      "■■■ epoch=19, val_acc=0.7949, val_loss=0.6618 \n",
      "■■■ epoch=20, val_acc=0.7949, val_loss=0.6801 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.7029 \n",
      "■■■ epoch=22, val_acc=0.7949, val_loss=0.7273 \n",
      "■■■ epoch=23, val_acc=0.7949, val_loss=0.7492 \n",
      "■■ base_i=4/5 (si=7, ki=1/4)\n",
      "■■■ epoch=1, val_acc=0.6154, val_loss=0.6896 \n",
      "■■■ epoch=2, val_acc=0.641, val_loss=0.6805 \n",
      "■■■ epoch=3, val_acc=0.6154, val_loss=0.6712 \n",
      "■■■ epoch=4, val_acc=0.641, val_loss=0.6587 \n",
      "■■■ epoch=5, val_acc=0.641, val_loss=0.6484 \n",
      "■■■ epoch=6, val_acc=0.641, val_loss=0.6365 \n",
      "■■■ epoch=7, val_acc=0.6667, val_loss=0.6268 \n",
      "■■■ epoch=8, val_acc=0.7179, val_loss=0.6208 \n",
      "■■■ epoch=9, val_acc=0.6923, val_loss=0.6158 \n",
      "■■■ epoch=10, val_acc=0.7692, val_loss=0.5856 \n",
      "■■■ epoch=11, val_acc=0.7436, val_loss=0.5562 \n",
      "■■■ epoch=12, val_acc=0.7436, val_loss=0.5788 \n",
      "■■■ epoch=13, val_acc=0.7692, val_loss=0.6111 \n",
      "■■■ epoch=14, val_acc=0.7692, val_loss=0.6612 \n",
      "■■■ epoch=15, val_acc=0.7949, val_loss=0.6982 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.6987 \n",
      "■■■ epoch=17, val_acc=0.7692, val_loss=0.6953 \n",
      "■■■ epoch=18, val_acc=0.7949, val_loss=0.704 \n",
      "■■■ epoch=19, val_acc=0.7949, val_loss=0.7164 \n",
      "■■■ epoch=20, val_acc=0.7949, val_loss=0.7307 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.7497 \n",
      "■ ki=2/4 (si=7)\n",
      "■■ base_i=0/5 (si=7, ki=2/4)\n",
      "■■■ epoch=1, val_acc=0.4615, val_loss=0.7024  #\n",
      "■■■ epoch=2, val_acc=0.5641, val_loss=0.681  #\n",
      "■■■ epoch=3, val_acc=0.5641, val_loss=0.6601  #\n",
      "■■■ epoch=4, val_acc=0.7179, val_loss=0.6166  #\n",
      "■■■ epoch=5, val_acc=0.6923, val_loss=0.5841  #\n",
      "■■■ epoch=6, val_acc=0.6923, val_loss=0.5769  #\n",
      "■■■ epoch=7, val_acc=0.6923, val_loss=0.5577  #\n",
      "■■■ epoch=8, val_acc=0.6923, val_loss=0.61 \n",
      "■■■ epoch=9, val_acc=0.6923, val_loss=0.6313 \n",
      "■■■ epoch=10, val_acc=0.7179, val_loss=0.5768 \n",
      "■■■ epoch=11, val_acc=0.7436, val_loss=0.5424  #\n",
      "■■■ epoch=12, val_acc=0.7179, val_loss=0.5432 \n",
      "■■■ epoch=13, val_acc=0.7179, val_loss=0.5748 \n",
      "■■■ epoch=14, val_acc=0.7436, val_loss=0.6206 \n",
      "■■■ epoch=15, val_acc=0.7436, val_loss=0.6997 \n",
      "■■■ epoch=16, val_acc=0.7179, val_loss=0.7861 \n",
      "■■■ epoch=17, val_acc=0.7179, val_loss=0.8538 \n",
      "■■■ epoch=18, val_acc=0.7179, val_loss=0.8302 \n",
      "■■■ epoch=19, val_acc=0.6923, val_loss=0.7688 \n",
      "■■■ epoch=20, val_acc=0.7179, val_loss=0.8262 \n",
      "■■■ epoch=21, val_acc=0.6667, val_loss=1.0586 \n",
      "■■ base_i=1/5 (si=7, ki=2/4)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.684 \n",
      "■■■ epoch=2, val_acc=0.5385, val_loss=0.666 \n",
      "■■■ epoch=3, val_acc=0.5641, val_loss=0.6471 \n",
      "■■■ epoch=4, val_acc=0.6667, val_loss=0.6216 \n",
      "■■■ epoch=5, val_acc=0.7436, val_loss=0.5706 \n",
      "■■■ epoch=6, val_acc=0.8205, val_loss=0.5175  #\n",
      "■■■ epoch=7, val_acc=0.7949, val_loss=0.5042  #\n",
      "■■■ epoch=8, val_acc=0.7692, val_loss=0.5078 \n",
      "■■■ epoch=9, val_acc=0.7949, val_loss=0.4318  #\n",
      "■■■ epoch=10, val_acc=0.8205, val_loss=0.4695 \n",
      "■■■ epoch=11, val_acc=0.7949, val_loss=0.4738 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.4983 \n",
      "■■■ epoch=13, val_acc=0.8205, val_loss=0.54 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.5655 \n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.5937 \n",
      "■■■ epoch=16, val_acc=0.7949, val_loss=0.6329 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.6739 \n",
      "■■■ epoch=18, val_acc=0.8205, val_loss=0.7126 \n",
      "■■■ epoch=19, val_acc=0.8205, val_loss=0.747 \n",
      "■■ base_i=2/5 (si=7, ki=2/4)\n",
      "■■■ epoch=1, val_acc=0.6154, val_loss=0.6899 \n",
      "■■■ epoch=2, val_acc=0.5641, val_loss=0.6824 \n",
      "■■■ epoch=3, val_acc=0.5641, val_loss=0.673 \n",
      "■■■ epoch=4, val_acc=0.641, val_loss=0.6532 \n",
      "■■■ epoch=5, val_acc=0.641, val_loss=0.6273 \n",
      "■■■ epoch=6, val_acc=0.6923, val_loss=0.5982 \n",
      "■■■ epoch=7, val_acc=0.6923, val_loss=0.565 \n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.5347 \n",
      "■■■ epoch=9, val_acc=0.7179, val_loss=0.5209 \n",
      "■■■ epoch=10, val_acc=0.7436, val_loss=0.4986 \n",
      "■■■ epoch=11, val_acc=0.7692, val_loss=0.4639 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.4737 \n",
      "■■■ epoch=13, val_acc=0.7692, val_loss=0.5394 \n",
      "■■■ epoch=14, val_acc=0.7692, val_loss=0.5875 \n",
      "■■■ epoch=15, val_acc=0.7692, val_loss=0.6173 \n",
      "■■■ epoch=16, val_acc=0.7949, val_loss=0.6259 \n",
      "■■■ epoch=17, val_acc=0.7949, val_loss=0.6276 \n",
      "■■■ epoch=18, val_acc=0.7692, val_loss=0.6262 \n",
      "■■■ epoch=19, val_acc=0.7692, val_loss=0.6357 \n",
      "■■■ epoch=20, val_acc=0.7692, val_loss=0.655 \n",
      "■■■ epoch=21, val_acc=0.7692, val_loss=0.6791 \n",
      "■■ base_i=3/5 (si=7, ki=2/4)\n",
      "■■■ epoch=1, val_acc=0.6154, val_loss=0.664 \n",
      "■■■ epoch=2, val_acc=0.6154, val_loss=0.6549 \n",
      "■■■ epoch=3, val_acc=0.6667, val_loss=0.6272 \n",
      "■■■ epoch=4, val_acc=0.7949, val_loss=0.5835 \n",
      "■■■ epoch=5, val_acc=0.6923, val_loss=0.5771 \n",
      "■■■ epoch=6, val_acc=0.6667, val_loss=0.5831 \n",
      "■■■ epoch=7, val_acc=0.7949, val_loss=0.4924 \n",
      "■■■ epoch=8, val_acc=0.7949, val_loss=0.4876 \n",
      "■■■ epoch=9, val_acc=0.7949, val_loss=0.4891 \n",
      "■■■ epoch=10, val_acc=0.7692, val_loss=0.446 \n",
      "■■■ epoch=11, val_acc=0.7692, val_loss=0.4481 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.4682 \n",
      "■■■ epoch=13, val_acc=0.7949, val_loss=0.5083 \n",
      "■■■ epoch=14, val_acc=0.7692, val_loss=0.5358 \n",
      "■■■ epoch=15, val_acc=0.7949, val_loss=0.5345 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.5399 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.5488 \n",
      "■■■ epoch=18, val_acc=0.8205, val_loss=0.5604 \n",
      "■■■ epoch=19, val_acc=0.8205, val_loss=0.5743 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.5885 \n",
      "■■ base_i=4/5 (si=7, ki=2/4)\n",
      "■■■ epoch=1, val_acc=0.4872, val_loss=0.6897 \n",
      "■■■ epoch=2, val_acc=0.5641, val_loss=0.6783 \n",
      "■■■ epoch=3, val_acc=0.641, val_loss=0.6545 \n",
      "■■■ epoch=4, val_acc=0.7179, val_loss=0.6339 \n",
      "■■■ epoch=5, val_acc=0.641, val_loss=0.626 \n",
      "■■■ epoch=6, val_acc=0.6667, val_loss=0.5958 \n",
      "■■■ epoch=7, val_acc=0.7692, val_loss=0.5438 \n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.5114 \n",
      "■■■ epoch=9, val_acc=0.7436, val_loss=0.5014 \n",
      "■■■ epoch=10, val_acc=0.7692, val_loss=0.4964 \n",
      "■■■ epoch=11, val_acc=0.7949, val_loss=0.503 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.5275 \n",
      "■■■ epoch=13, val_acc=0.7949, val_loss=0.5644 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.5936 \n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.6198 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.6398 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.6546 \n",
      "■■■ epoch=18, val_acc=0.8462, val_loss=0.6734 \n",
      "■■■ epoch=19, val_acc=0.8462, val_loss=0.7029 \n",
      "■■■ epoch=20, val_acc=0.8462, val_loss=0.7382 \n",
      "■ ki=3/4 (si=7)\n",
      "■■ base_i=0/5 (si=7, ki=3/4)\n",
      "■■■ epoch=1, val_acc=0.4615, val_loss=0.6732  #\n",
      "■■■ epoch=2, val_acc=0.6154, val_loss=0.653  #\n",
      "■■■ epoch=3, val_acc=0.6923, val_loss=0.6327  #\n",
      "■■■ epoch=4, val_acc=0.6923, val_loss=0.5821  #\n",
      "■■■ epoch=5, val_acc=0.7692, val_loss=0.5326  #\n",
      "■■■ epoch=6, val_acc=0.7692, val_loss=0.4988  #\n",
      "■■■ epoch=7, val_acc=0.7692, val_loss=0.4922  #\n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.5137 \n",
      "■■■ epoch=9, val_acc=0.7436, val_loss=0.5276 \n",
      "■■■ epoch=10, val_acc=0.8205, val_loss=0.4926 \n",
      "■■■ epoch=11, val_acc=0.7949, val_loss=0.5151 \n",
      "■■■ epoch=12, val_acc=0.7692, val_loss=0.5356 \n",
      "■■■ epoch=13, val_acc=0.7949, val_loss=0.5698 \n",
      "■■■ epoch=14, val_acc=0.7949, val_loss=0.6076 \n",
      "■■■ epoch=15, val_acc=0.7692, val_loss=0.6039 \n",
      "■■■ epoch=16, val_acc=0.7949, val_loss=0.5942 \n",
      "■■■ epoch=17, val_acc=0.7949, val_loss=0.6484 \n",
      "■■ base_i=1/5 (si=7, ki=3/4)\n",
      "■■■ epoch=1, val_acc=0.641, val_loss=0.6668 \n",
      "■■■ epoch=2, val_acc=0.6667, val_loss=0.6515 \n",
      "■■■ epoch=3, val_acc=0.6923, val_loss=0.6223 \n",
      "■■■ epoch=4, val_acc=0.6923, val_loss=0.5872 \n",
      "■■■ epoch=5, val_acc=0.8205, val_loss=0.5422 \n",
      "■■■ epoch=6, val_acc=0.8205, val_loss=0.4908  #\n",
      "■■■ epoch=7, val_acc=0.8462, val_loss=0.449  #\n",
      "■■■ epoch=8, val_acc=0.8718, val_loss=0.3974  #\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■ epoch=9, val_acc=0.8718, val_loss=0.3505  #\n",
      "■■■ epoch=10, val_acc=0.8462, val_loss=0.358 \n",
      "■■■ epoch=11, val_acc=0.8718, val_loss=0.3369  #\n",
      "■■■ epoch=12, val_acc=0.8462, val_loss=0.4143 \n",
      "■■■ epoch=13, val_acc=0.8462, val_loss=0.5031 \n",
      "■■■ epoch=14, val_acc=0.8462, val_loss=0.5181 \n",
      "■■■ epoch=15, val_acc=0.8462, val_loss=0.5159 \n",
      "■■■ epoch=16, val_acc=0.8462, val_loss=0.5058 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.4961 \n",
      "■■■ epoch=18, val_acc=0.8462, val_loss=0.494 \n",
      "■■■ epoch=19, val_acc=0.8718, val_loss=0.5026 \n",
      "■■■ epoch=20, val_acc=0.8462, val_loss=0.5178 \n",
      "■■■ epoch=21, val_acc=0.8462, val_loss=0.5339 \n",
      "■■ base_i=2/5 (si=7, ki=3/4)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.6908 \n",
      "■■■ epoch=2, val_acc=0.5641, val_loss=0.6826 \n",
      "■■■ epoch=3, val_acc=0.6923, val_loss=0.6679 \n",
      "■■■ epoch=4, val_acc=0.6923, val_loss=0.644 \n",
      "■■■ epoch=5, val_acc=0.7179, val_loss=0.6262 \n",
      "■■■ epoch=6, val_acc=0.6923, val_loss=0.6091 \n",
      "■■■ epoch=7, val_acc=0.7179, val_loss=0.5718 \n",
      "■■■ epoch=8, val_acc=0.7179, val_loss=0.5355 \n",
      "■■■ epoch=9, val_acc=0.7436, val_loss=0.5179 \n",
      "■■■ epoch=10, val_acc=0.7692, val_loss=0.434 \n",
      "■■■ epoch=11, val_acc=0.7692, val_loss=0.3834 \n",
      "■■■ epoch=12, val_acc=0.7436, val_loss=0.4005 \n",
      "■■■ epoch=13, val_acc=0.7692, val_loss=0.3775 \n",
      "■■■ epoch=14, val_acc=0.7949, val_loss=0.321  #\n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.2914  #\n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.2798  #\n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.2834 \n",
      "■■■ epoch=18, val_acc=0.8205, val_loss=0.2954 \n",
      "■■■ epoch=19, val_acc=0.8205, val_loss=0.3155 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.3443 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.3656 \n",
      "■■■ epoch=22, val_acc=0.8205, val_loss=0.3694 \n",
      "■■■ epoch=23, val_acc=0.8205, val_loss=0.3671 \n",
      "■■■ epoch=24, val_acc=0.8205, val_loss=0.3622 \n",
      "■■■ epoch=25, val_acc=0.8205, val_loss=0.3573 \n",
      "■■■ epoch=26, val_acc=0.8205, val_loss=0.3546 \n",
      "■■ base_i=3/5 (si=7, ki=3/4)\n",
      "■■■ epoch=1, val_acc=0.6154, val_loss=0.6794 \n",
      "■■■ epoch=2, val_acc=0.4872, val_loss=0.6622 \n",
      "■■■ epoch=3, val_acc=0.5385, val_loss=0.6479 \n",
      "■■■ epoch=4, val_acc=0.6923, val_loss=0.6207 \n",
      "■■■ epoch=5, val_acc=0.6923, val_loss=0.5955 \n",
      "■■■ epoch=6, val_acc=0.6154, val_loss=0.6049 \n",
      "■■■ epoch=7, val_acc=0.6923, val_loss=0.5542 \n",
      "■■■ epoch=8, val_acc=0.7179, val_loss=0.5457 \n",
      "■■■ epoch=9, val_acc=0.7179, val_loss=0.5143 \n",
      "■■■ epoch=10, val_acc=0.7436, val_loss=0.4914 \n",
      "■■■ epoch=11, val_acc=0.7949, val_loss=0.4697 \n",
      "■■■ epoch=12, val_acc=0.7949, val_loss=0.477 \n",
      "■■■ epoch=13, val_acc=0.7949, val_loss=0.4574 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.4632 \n",
      "■■■ epoch=15, val_acc=0.8205, val_loss=0.4756 \n",
      "■■■ epoch=16, val_acc=0.8205, val_loss=0.4738 \n",
      "■■■ epoch=17, val_acc=0.8205, val_loss=0.4814 \n",
      "■■■ epoch=18, val_acc=0.7949, val_loss=0.5034 \n",
      "■■■ epoch=19, val_acc=0.7949, val_loss=0.5313 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.5509 \n",
      "■■■ epoch=21, val_acc=0.8205, val_loss=0.5616 \n",
      "■■■ epoch=22, val_acc=0.7949, val_loss=0.5689 \n",
      "■■■ epoch=23, val_acc=0.7949, val_loss=0.5764 \n",
      "■■ base_i=4/5 (si=7, ki=3/4)\n",
      "■■■ epoch=1, val_acc=0.6667, val_loss=0.6764 \n",
      "■■■ epoch=2, val_acc=0.6154, val_loss=0.6578 \n",
      "■■■ epoch=3, val_acc=0.6154, val_loss=0.639 \n",
      "■■■ epoch=4, val_acc=0.6667, val_loss=0.6149 \n",
      "■■■ epoch=5, val_acc=0.7179, val_loss=0.5823 \n",
      "■■■ epoch=6, val_acc=0.7179, val_loss=0.5475 \n",
      "■■■ epoch=7, val_acc=0.7436, val_loss=0.5038 \n",
      "■■■ epoch=8, val_acc=0.7179, val_loss=0.4645 \n",
      "■■■ epoch=9, val_acc=0.8205, val_loss=0.4167 \n",
      "■■■ epoch=10, val_acc=0.8205, val_loss=0.3967 \n",
      "■■■ epoch=11, val_acc=0.8205, val_loss=0.3916 \n",
      "■■■ epoch=12, val_acc=0.8205, val_loss=0.4056 \n",
      "■■■ epoch=13, val_acc=0.8205, val_loss=0.4003 \n",
      "■■■ epoch=14, val_acc=0.8205, val_loss=0.3981 \n",
      "■■■ epoch=15, val_acc=0.8462, val_loss=0.4019 \n",
      "■■■ epoch=16, val_acc=0.8462, val_loss=0.4092 \n",
      "■■■ epoch=17, val_acc=0.8462, val_loss=0.4189 \n",
      "■■■ epoch=18, val_acc=0.8462, val_loss=0.4304 \n",
      "■■■ epoch=19, val_acc=0.8205, val_loss=0.4447 \n",
      "■■■ epoch=20, val_acc=0.8205, val_loss=0.4591 \n",
      "■■■ epoch=21, val_acc=0.8205, val_loss=0.4722 \n",
      "■ Saved in the params folder at Wed Jun 21 16:06:23 2023.\n",
      "■ stopped epochs: [10 11  9 16]\n",
      "■ stopped confs:  [0.8204 0.8771 0.898 ] [0.9711 0.9721 0.9729]\n",
      "##################################################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('Calculate a trn-conf criterion.')\n",
    "##################################################\n",
    "k_folds = 4 # number of cv folds\n",
    "model_dropout = nn.Dropout(dr).to(device)\n",
    "##################################################\n",
    "\n",
    "print(50*'#')\n",
    "print(f'si={si}')\n",
    "\n",
    "if not os.path.exists(f'./params/stop_infs_si{si}.bin'):\n",
    "    all_lab_examples, _, _ = fs.divide_samples(examples,si=si,use_rate=use_rate,trn_rate=1.0) \n",
    "    all_lab_len = len(all_lab_examples)\n",
    "    all_lab_wmat = np.ones((4,all_lab_len))\n",
    "    all_lab_cmat = np.zeros((4,all_lab_len))\n",
    "    all_lab_arrow = fs.example2arrow(all_lab_examples, label_map)\n",
    "\n",
    "    dev_stop_epochs = []\n",
    "    for ki in range(k_folds):\n",
    "        print(f'■ ki={ki}/{k_folds} (si={si})')\n",
    "\n",
    "        k_step = all_lab_len//k_folds + 1\n",
    "        sel_indices = [i%all_lab_len for i in range(ki*k_step, (ki+1)*k_step)]\n",
    "        trn_examples = fs.select_by_index(all_lab_examples,sel_indices,reverse=True)\n",
    "        dev_examples = fs.select_by_index(all_lab_examples,sel_indices,reverse=False)\n",
    "        for ii in sel_indices:\n",
    "            all_lab_wmat[ki][ii] = 0.0\n",
    "\n",
    "        trn_arrow = fs.example2arrow(trn_examples, label_map)\n",
    "        dev_arrow = fs.example2arrow(dev_examples, label_map)\n",
    "        tst_arrow = fs.example2arrow(tst_examples, label_map)\n",
    "        trn_len,dev_len,tst_len = len(trn_arrow),len(dev_arrow),len(tst_arrow)\n",
    "\n",
    "        best_val_loss = np.inf\n",
    "        for base_i in range(n_base):\n",
    "            model.init_weights()\n",
    "            model.load_state_dict(init_state_dict)\n",
    "\n",
    "            print(f'■■ base_i={base_i}/{n_base} (si={si}, ki={ki}/{k_folds})')\n",
    "\n",
    "            classifier = nn.Linear(num_features, len(label_list)).to(device) \n",
    "            classifier.weight.data = torch.from_numpy(dense_wbs_set[base_i][0]).to(device)\n",
    "            classifier.bias.data = torch.from_numpy(dense_wbs_set[base_i][1]).to(device)\n",
    "            optimizer = torch.optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=lr)\n",
    "\n",
    "            max_val_loss = np.inf\n",
    "            num_patience = 0\n",
    "            for epoch in range(1,epochs+1):\n",
    "                batch_indices = np.random.permutation(trn_len)\n",
    "                for ti in range(trn_len//btchs):\n",
    "                    bat_indices = batch_indices[ti*btchs:(ti+1)*btchs]\n",
    "                    X_bat, y_bat = fs.arrow2batch(trn_arrow, bat_indices, tokenizer, max_length, device)\n",
    "\n",
    "                    model.train()\n",
    "                    bat_vectors = model(**X_bat).pooler_output\n",
    "                    bat_logits = classifier(model_dropout(bat_vectors))\n",
    "                    bat_loss = cross_entropy(bat_logits, y_bat)\n",
    "                    model.zero_grad()\n",
    "                    bat_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                suffix = ''\n",
    "                val_acc, val_loss = fs.eval_accuracy(dev_arrow, 2*btchs, model, tokenizer, max_length, classifier, device)\n",
    "                if best_val_loss>val_loss:\n",
    "                    best_val_loss=val_loss\n",
    "                    dev_stop_epoch = epoch\n",
    "                    all_lab_golds,all_lab_probs = fs.eval_accuracy(all_lab_arrow, 2*btchs, model, tokenizer, \n",
    "                                                                   max_length, classifier, device, True)\n",
    "                    all_lab_cmat[ki] = all_lab_wmat[ki]*all_lab_probs.max(1)\n",
    "                    suffix = ' #'\n",
    "\n",
    "                if max_val_loss > val_loss:\n",
    "                    max_val_loss = val_loss\n",
    "                    num_patience = 0\n",
    "                else:\n",
    "                    num_patience += 1\n",
    "                if num_patience > 10:\n",
    "                    break\n",
    "                print(f'■■■ epoch={epoch}, val_acc={round(val_acc,4)}, val_loss={round(val_loss,4)} {suffix}')\n",
    "\n",
    "        dev_stop_epochs.append(dev_stop_epoch)\n",
    "\n",
    "    dev_stop_epochs = np.array(dev_stop_epochs)\n",
    "    ref_confs = np.sort((all_lab_cmat.sum(0) / (all_lab_wmat.sum(0)+1e-9) ))\n",
    "\n",
    "    fs.dump_all([dev_stop_epochs, ref_confs] , f'./params/stop_infs_si{si}.bin')\n",
    "    print(f'■ Saved in the params folder at {time.ctime()}.')\n",
    "else:\n",
    "    dev_stop_epochs, ref_confs = fs.dump_all(f'./params/stop_infs_si{si}.bin')\n",
    "    print(f'■ Load the stop information.')\n",
    "\n",
    "print('■ stopped epochs:',dev_stop_epochs)\n",
    "print('■ stopped confs: ',np.around(ref_confs[:3],4), np.around(ref_confs[-3:],4))\n",
    "print(50*'#')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b9e5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WA-init algorithm: Phase-1 finds a good parameter set\n",
      "##################################################\n",
      "si=7\n",
      "■ ri=0/2 (si=7)\n",
      "■■ base_i=0/5 (si=7, ri=0/2)\n",
      "■■■ epoch=1, val_acc=0.4744, val_loss=0.7284  #\n",
      "■■■ epoch=2, val_acc=0.5256, val_loss=0.7158  #\n",
      "■■■ epoch=3, val_acc=0.5769, val_loss=0.7121  #\n",
      "■■■ epoch=4, val_acc=0.5897, val_loss=0.6871  #\n",
      "■■■ epoch=5, val_acc=0.5897, val_loss=0.668  #\n",
      "■■■ epoch=6, val_acc=0.6026, val_loss=0.6572  #\n",
      "■■■ epoch=7, val_acc=0.6538, val_loss=0.6359  #\n",
      "■■■ epoch=8, val_acc=0.6538, val_loss=0.6768 \n",
      "■■■ epoch=9, val_acc=0.6154, val_loss=0.7494 \n",
      "■■■ epoch=10, val_acc=0.6282, val_loss=0.7497 \n",
      "■■■ epoch=11, val_acc=0.6538, val_loss=0.7179 \n",
      "■■■ epoch=12, val_acc=0.6667, val_loss=0.7708 \n",
      "■■■ epoch=13, val_acc=0.641, val_loss=0.7935 \n",
      "■■■ epoch=14, val_acc=0.6538, val_loss=0.8128 \n",
      "■■■ epoch=15, val_acc=0.6282, val_loss=0.8325 \n",
      "■■■ epoch=16, val_acc=0.6282, val_loss=0.8469 \n",
      "■■■ epoch=17, val_acc=0.6282, val_loss=0.8916 \n",
      "■■ base_i=1/5 (si=7, ri=0/2)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.6948 \n",
      "■■■ epoch=2, val_acc=0.5513, val_loss=0.6852 \n",
      "■■■ epoch=3, val_acc=0.5385, val_loss=0.6696 \n",
      "■■■ epoch=4, val_acc=0.5897, val_loss=0.6595 \n",
      "■■■ epoch=5, val_acc=0.6795, val_loss=0.6445 \n",
      "■■■ epoch=6, val_acc=0.6923, val_loss=0.6289  #\n",
      "■■■ epoch=7, val_acc=0.7051, val_loss=0.6162  #\n",
      "■■■ epoch=8, val_acc=0.6923, val_loss=0.5996  #\n",
      "■■■ epoch=9, val_acc=0.7051, val_loss=0.5808  #\n",
      "■■■ epoch=10, val_acc=0.7308, val_loss=0.5598  #\n",
      "■■■ epoch=11, val_acc=0.7692, val_loss=0.5381  #\n",
      "■■■ epoch=12, val_acc=0.7821, val_loss=0.523  #\n",
      "■■■ epoch=13, val_acc=0.7821, val_loss=0.5057  #\n",
      "■■■ epoch=14, val_acc=0.7692, val_loss=0.4901  #\n",
      "■■■ epoch=15, val_acc=0.8077, val_loss=0.493 \n",
      "■■■ epoch=16, val_acc=0.7692, val_loss=0.5029 \n",
      "■■■ epoch=17, val_acc=0.7821, val_loss=0.5125 \n",
      "■■■ epoch=18, val_acc=0.7821, val_loss=0.5268 \n",
      "■■■ epoch=19, val_acc=0.7821, val_loss=0.5395 \n",
      "■■■ epoch=20, val_acc=0.7949, val_loss=0.5494 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.5601 \n",
      "■■■ epoch=22, val_acc=0.8077, val_loss=0.5703 \n",
      "■■■ epoch=23, val_acc=0.8205, val_loss=0.5809 \n",
      "■■■ epoch=24, val_acc=0.8205, val_loss=0.591 \n",
      "■■ base_i=2/5 (si=7, ri=0/2)\n",
      "■■■ epoch=1, val_acc=0.4487, val_loss=0.6995 \n",
      "■■■ epoch=2, val_acc=0.5256, val_loss=0.6938 \n",
      "■■■ epoch=3, val_acc=0.5256, val_loss=0.6895 \n",
      "■■■ epoch=4, val_acc=0.5897, val_loss=0.6845 \n",
      "■■■ epoch=5, val_acc=0.5513, val_loss=0.6845 \n",
      "■■■ epoch=6, val_acc=0.5256, val_loss=0.6788 \n",
      "■■■ epoch=7, val_acc=0.5256, val_loss=0.6902 \n",
      "■■■ epoch=8, val_acc=0.5897, val_loss=0.6754 \n",
      "■■■ epoch=9, val_acc=0.641, val_loss=0.6684 \n",
      "■■■ epoch=10, val_acc=0.6154, val_loss=0.6656 \n",
      "■■■ epoch=11, val_acc=0.6282, val_loss=0.6593 \n",
      "■■■ epoch=12, val_acc=0.641, val_loss=0.6518 \n",
      "■■■ epoch=13, val_acc=0.6667, val_loss=0.6424 \n",
      "■■■ epoch=14, val_acc=0.6795, val_loss=0.6316 \n",
      "■■■ epoch=15, val_acc=0.6923, val_loss=0.6256 \n",
      "■■■ epoch=16, val_acc=0.7051, val_loss=0.6281 \n",
      "■■■ epoch=17, val_acc=0.7436, val_loss=0.6336 \n",
      "■■■ epoch=18, val_acc=0.7436, val_loss=0.645 \n",
      "■■■ epoch=19, val_acc=0.7436, val_loss=0.6617 \n",
      "■■■ epoch=20, val_acc=0.7436, val_loss=0.6779 \n",
      "■■■ epoch=21, val_acc=0.7436, val_loss=0.6955 \n",
      "■■■ epoch=22, val_acc=0.7564, val_loss=0.7125 \n",
      "■■■ epoch=23, val_acc=0.7564, val_loss=0.7292 \n",
      "■■■ epoch=24, val_acc=0.7564, val_loss=0.7424 \n",
      "■■■ epoch=25, val_acc=0.7564, val_loss=0.7456 \n",
      "■■ base_i=3/5 (si=7, ri=0/2)\n",
      "■■■ epoch=1, val_acc=0.5128, val_loss=0.6844 \n",
      "■■■ epoch=2, val_acc=0.5513, val_loss=0.6709 \n",
      "■■■ epoch=3, val_acc=0.6923, val_loss=0.6578 \n",
      "■■■ epoch=4, val_acc=0.7051, val_loss=0.6458 \n",
      "■■■ epoch=5, val_acc=0.6154, val_loss=0.6437 \n",
      "■■■ epoch=6, val_acc=0.641, val_loss=0.6363 \n",
      "■■■ epoch=7, val_acc=0.6923, val_loss=0.6136 \n",
      "■■■ epoch=8, val_acc=0.7308, val_loss=0.5855 \n",
      "■■■ epoch=9, val_acc=0.7436, val_loss=0.5656 \n",
      "■■■ epoch=10, val_acc=0.7436, val_loss=0.5451 \n",
      "■■■ epoch=11, val_acc=0.7436, val_loss=0.5312 \n",
      "■■■ epoch=12, val_acc=0.7821, val_loss=0.5319 \n",
      "■■■ epoch=13, val_acc=0.7179, val_loss=0.572 \n",
      "■■■ epoch=14, val_acc=0.7179, val_loss=0.5933 \n",
      "■■■ epoch=15, val_acc=0.7179, val_loss=0.5966 \n",
      "■■■ epoch=16, val_acc=0.7564, val_loss=0.5622 \n",
      "■■■ epoch=17, val_acc=0.7821, val_loss=0.5461 \n",
      "■■■ epoch=18, val_acc=0.7949, val_loss=0.5494 \n",
      "■■■ epoch=19, val_acc=0.7949, val_loss=0.5607 \n",
      "■■■ epoch=20, val_acc=0.7949, val_loss=0.5758 \n",
      "■■■ epoch=21, val_acc=0.7949, val_loss=0.5923 \n",
      "■■ base_i=4/5 (si=7, ri=0/2)\n",
      "■■■ epoch=1, val_acc=0.4744, val_loss=0.6898 \n",
      "■■■ epoch=2, val_acc=0.7051, val_loss=0.6798 \n",
      "■■■ epoch=3, val_acc=0.6154, val_loss=0.6697 \n",
      "■■■ epoch=4, val_acc=0.6282, val_loss=0.6582 \n",
      "■■■ epoch=5, val_acc=0.6026, val_loss=0.6534 \n",
      "■■■ epoch=6, val_acc=0.6026, val_loss=0.6547 \n",
      "■■■ epoch=7, val_acc=0.5897, val_loss=0.6387 \n",
      "■■■ epoch=8, val_acc=0.6795, val_loss=0.6037 \n",
      "■■■ epoch=9, val_acc=0.7051, val_loss=0.5813 \n",
      "■■■ epoch=10, val_acc=0.7308, val_loss=0.5662 \n",
      "■■■ epoch=11, val_acc=0.6923, val_loss=0.5819 \n",
      "■■■ epoch=12, val_acc=0.6795, val_loss=0.6074 \n",
      "■■■ epoch=13, val_acc=0.6795, val_loss=0.612 \n",
      "■■■ epoch=14, val_acc=0.7179, val_loss=0.6068 \n",
      "■■■ epoch=15, val_acc=0.7308, val_loss=0.6086 \n",
      "■■■ epoch=16, val_acc=0.7308, val_loss=0.618 \n",
      "■■■ epoch=17, val_acc=0.7308, val_loss=0.6384 \n",
      "■■■ epoch=18, val_acc=0.7179, val_loss=0.6626 \n",
      "■■■ epoch=19, val_acc=0.7179, val_loss=0.6785 \n",
      "■■■ epoch=20, val_acc=0.7179, val_loss=0.6905 \n",
      "■ Saved the parameters at Wed Jun 21 16:08:46 2023.\n",
      "■ ri=1/2 (si=7)\n",
      "■■ base_i=0/5 (si=7, ri=1/2)\n",
      "■■■ epoch=1, val_acc=0.4615, val_loss=0.6951  #\n",
      "■■■ epoch=2, val_acc=0.5128, val_loss=0.6848  #\n",
      "■■■ epoch=3, val_acc=0.5513, val_loss=0.6759  #\n",
      "■■■ epoch=4, val_acc=0.6795, val_loss=0.6665  #\n",
      "■■■ epoch=5, val_acc=0.6667, val_loss=0.6513  #\n",
      "■■■ epoch=6, val_acc=0.6667, val_loss=0.6304  #\n",
      "■■■ epoch=7, val_acc=0.6282, val_loss=0.691 \n",
      "■■■ epoch=8, val_acc=0.6026, val_loss=0.6923 \n",
      "■■■ epoch=9, val_acc=0.6667, val_loss=0.6167  #\n",
      "■■■ epoch=10, val_acc=0.7308, val_loss=0.5683  #\n",
      "■■■ epoch=11, val_acc=0.7308, val_loss=0.5654  #\n",
      "■■■ epoch=12, val_acc=0.7436, val_loss=0.5597  #\n",
      "■■■ epoch=13, val_acc=0.7179, val_loss=0.5837 \n",
      "■■■ epoch=14, val_acc=0.6795, val_loss=0.6401 \n",
      "■■■ epoch=15, val_acc=0.7051, val_loss=0.6934 \n",
      "■■■ epoch=16, val_acc=0.6667, val_loss=0.7538 \n",
      "■■■ epoch=17, val_acc=0.6667, val_loss=0.8038 \n",
      "■■■ epoch=18, val_acc=0.6667, val_loss=0.8255 \n",
      "■■■ epoch=19, val_acc=0.6667, val_loss=0.8349 \n",
      "■■■ epoch=20, val_acc=0.6667, val_loss=0.8422 \n",
      "■■■ epoch=21, val_acc=0.6667, val_loss=0.8498 \n",
      "■■■ epoch=22, val_acc=0.6667, val_loss=0.8563 \n",
      "■■ base_i=1/5 (si=7, ri=1/2)\n",
      "■■■ epoch=1, val_acc=0.5385, val_loss=0.6907 \n",
      "■■■ epoch=2, val_acc=0.5385, val_loss=0.6804 \n",
      "■■■ epoch=3, val_acc=0.5641, val_loss=0.665 \n",
      "■■■ epoch=4, val_acc=0.6154, val_loss=0.6498 \n",
      "■■■ epoch=5, val_acc=0.6923, val_loss=0.6323 \n",
      "■■■ epoch=6, val_acc=0.7179, val_loss=0.6134 \n",
      "■■■ epoch=7, val_acc=0.7436, val_loss=0.5898 \n",
      "■■■ epoch=8, val_acc=0.7436, val_loss=0.569 \n",
      "■■■ epoch=9, val_acc=0.7821, val_loss=0.5449  #\n",
      "■■■ epoch=10, val_acc=0.7692, val_loss=0.5232  #\n",
      "■■■ epoch=11, val_acc=0.8205, val_loss=0.5004  #\n",
      "■■■ epoch=12, val_acc=0.8205, val_loss=0.4909  #\n",
      "■■■ epoch=13, val_acc=0.8205, val_loss=0.4917 \n",
      "■■■ epoch=14, val_acc=0.8077, val_loss=0.5063 \n",
      "■■■ epoch=15, val_acc=0.7692, val_loss=0.5317 \n",
      "■■■ epoch=16, val_acc=0.7692, val_loss=0.558 \n",
      "■■■ epoch=17, val_acc=0.7692, val_loss=0.5717 \n",
      "■■■ epoch=18, val_acc=0.7692, val_loss=0.582 \n",
      "■■■ epoch=19, val_acc=0.7564, val_loss=0.5928 \n",
      "■■■ epoch=20, val_acc=0.7564, val_loss=0.6076 \n",
      "■■■ epoch=21, val_acc=0.7564, val_loss=0.6299 \n",
      "■■■ epoch=22, val_acc=0.7564, val_loss=0.656 \n",
      "■■ base_i=2/5 (si=7, ri=1/2)\n",
      "■■■ epoch=1, val_acc=0.5513, val_loss=0.6978 \n",
      "■■■ epoch=2, val_acc=0.5769, val_loss=0.6898 \n",
      "■■■ epoch=3, val_acc=0.6154, val_loss=0.6842 \n",
      "■■■ epoch=4, val_acc=0.5897, val_loss=0.6761 \n",
      "■■■ epoch=5, val_acc=0.5897, val_loss=0.6648 \n",
      "■■■ epoch=6, val_acc=0.5513, val_loss=0.663 \n",
      "■■■ epoch=7, val_acc=0.5385, val_loss=0.6701 \n",
      "■■■ epoch=8, val_acc=0.5769, val_loss=0.6474 \n",
      "■■■ epoch=9, val_acc=0.6538, val_loss=0.6217 \n",
      "■■■ epoch=10, val_acc=0.641, val_loss=0.6066 \n",
      "■■■ epoch=11, val_acc=0.6538, val_loss=0.5994 \n",
      "■■■ epoch=12, val_acc=0.6795, val_loss=0.5948 \n",
      "■■■ epoch=13, val_acc=0.6538, val_loss=0.5973 \n",
      "■■■ epoch=14, val_acc=0.7179, val_loss=0.596 \n",
      "■■■ epoch=15, val_acc=0.7051, val_loss=0.5835 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■■■ epoch=16, val_acc=0.7051, val_loss=0.5859 \n",
      "■■■ epoch=17, val_acc=0.7179, val_loss=0.6028 \n",
      "■■■ epoch=18, val_acc=0.7179, val_loss=0.6125 \n",
      "■■■ epoch=19, val_acc=0.7308, val_loss=0.6036 \n",
      "■■■ epoch=20, val_acc=0.7308, val_loss=0.6021 \n",
      "■■■ epoch=21, val_acc=0.7179, val_loss=0.6091 \n",
      "■■■ epoch=22, val_acc=0.7436, val_loss=0.6183 \n",
      "■■■ epoch=23, val_acc=0.7436, val_loss=0.6267 \n",
      "■■■ epoch=24, val_acc=0.7436, val_loss=0.6337 \n",
      "■■■ epoch=25, val_acc=0.7436, val_loss=0.6394 \n",
      "■■ base_i=3/5 (si=7, ri=1/2)\n",
      "■■■ epoch=1, val_acc=0.5128, val_loss=0.6956 \n",
      "■■■ epoch=2, val_acc=0.5256, val_loss=0.6848 \n",
      "■■■ epoch=3, val_acc=0.5641, val_loss=0.6717 \n",
      "■■■ epoch=4, val_acc=0.6923, val_loss=0.6597 \n",
      "■■■ epoch=5, val_acc=0.7051, val_loss=0.6448 \n",
      "■■■ epoch=6, val_acc=0.6282, val_loss=0.6327 \n",
      "■■■ epoch=7, val_acc=0.5897, val_loss=0.632 \n",
      "■■■ epoch=8, val_acc=0.6154, val_loss=0.62 \n",
      "■■■ epoch=9, val_acc=0.641, val_loss=0.6017 \n",
      "■■■ epoch=10, val_acc=0.6538, val_loss=0.5929 \n",
      "■■■ epoch=11, val_acc=0.641, val_loss=0.5803 \n",
      "■■■ epoch=12, val_acc=0.6923, val_loss=0.5701 \n",
      "■■■ epoch=13, val_acc=0.6923, val_loss=0.5678 \n",
      "■■■ epoch=14, val_acc=0.7051, val_loss=0.5738 \n",
      "■■■ epoch=15, val_acc=0.7179, val_loss=0.5875 \n",
      "■■■ epoch=16, val_acc=0.7179, val_loss=0.5915 \n",
      "■■■ epoch=17, val_acc=0.7564, val_loss=0.589 \n",
      "■■■ epoch=18, val_acc=0.7692, val_loss=0.5943 \n",
      "■■■ epoch=19, val_acc=0.7821, val_loss=0.606 \n",
      "■■■ epoch=20, val_acc=0.7564, val_loss=0.6229 \n",
      "■■■ epoch=21, val_acc=0.7436, val_loss=0.642 \n",
      "■■■ epoch=22, val_acc=0.7308, val_loss=0.6602 \n",
      "■■■ epoch=23, val_acc=0.7436, val_loss=0.6732 \n",
      "■■ base_i=4/5 (si=7, ri=1/2)\n",
      "■■■ epoch=1, val_acc=0.6154, val_loss=0.6902 \n",
      "■■■ epoch=2, val_acc=0.6154, val_loss=0.687 \n",
      "■■■ epoch=3, val_acc=0.5641, val_loss=0.6831 \n",
      "■■■ epoch=4, val_acc=0.5897, val_loss=0.6754 \n",
      "■■■ epoch=5, val_acc=0.5385, val_loss=0.6701 \n",
      "■■■ epoch=6, val_acc=0.5385, val_loss=0.6653 \n",
      "■■■ epoch=7, val_acc=0.5769, val_loss=0.6567 \n",
      "■■■ epoch=8, val_acc=0.641, val_loss=0.643 \n",
      "■■■ epoch=9, val_acc=0.6538, val_loss=0.6269 \n",
      "■■■ epoch=10, val_acc=0.641, val_loss=0.6082 \n",
      "■■■ epoch=11, val_acc=0.6795, val_loss=0.591 \n",
      "■■■ epoch=12, val_acc=0.7179, val_loss=0.5819 \n",
      "■■■ epoch=13, val_acc=0.7308, val_loss=0.5635 \n",
      "■■■ epoch=14, val_acc=0.7308, val_loss=0.5497 \n",
      "■■■ epoch=15, val_acc=0.7436, val_loss=0.5465 \n",
      "■■■ epoch=16, val_acc=0.7692, val_loss=0.5503 \n",
      "■■■ epoch=17, val_acc=0.7949, val_loss=0.5606 \n",
      "■■■ epoch=18, val_acc=0.7692, val_loss=0.581 \n",
      "■■■ epoch=19, val_acc=0.7692, val_loss=0.6087 \n",
      "■■■ epoch=20, val_acc=0.7564, val_loss=0.6367 \n",
      "■■■ epoch=21, val_acc=0.7564, val_loss=0.661 \n",
      "■■■ epoch=22, val_acc=0.7692, val_loss=0.6795 \n",
      "■■■ epoch=23, val_acc=0.7692, val_loss=0.6943 \n",
      "■■■ epoch=24, val_acc=0.7821, val_loss=0.7068 \n",
      "■■■ epoch=25, val_acc=0.7949, val_loss=0.7187 \n",
      "■ Saved the parameters at Wed Jun 21 16:09:45 2023.\n",
      "##################################################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('WA-init algorithm: Phase-1 finds a good parameter set')\n",
    "##################################################\n",
    "trn_rate = 0.5 # trn/val ratio\n",
    "num_repeats = 2 # number of sample split\n",
    "model_dropout = nn.Dropout(dr).to(device)\n",
    "##################################################\n",
    "\n",
    "print(50*'#')\n",
    "print(f'si={si}')\n",
    "\n",
    "lab_examples, _, _ = fs.divide_samples(examples, si=si, use_rate=use_rate, trn_rate=1.0)\n",
    "lab_len = len(lab_examples)\n",
    "trn_num = int(lab_len*trn_rate+0.5)\n",
    "\n",
    "for ri in range(num_repeats):\n",
    "    print(f'■ ri={ri}/{num_repeats} (si={si})')\n",
    "\n",
    "    start_i = int(ri*(lab_len/num_repeats))\n",
    "    sel_indices = [i%lab_len for i in range(start_i, start_i+trn_num)]\n",
    "    trn_examples = fs.select_by_index(lab_examples, sel_indices, reverse=True)\n",
    "    dev_examples = fs.select_by_index(lab_examples, sel_indices, reverse=False)\n",
    "\n",
    "    trn_arrow = fs.example2arrow(trn_examples, label_map)\n",
    "    dev_arrow = fs.example2arrow(dev_examples, label_map)\n",
    "    tst_arrow = fs.example2arrow(tst_examples, label_map)\n",
    "    trn_len,dev_len,tst_len = len(trn_arrow),len(dev_arrow),len(tst_arrow)\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    for base_i in range(n_base):\n",
    "        model.init_weights()\n",
    "        model.load_state_dict(init_state_dict)\n",
    "        #print( list(model.parameters())[2] )\n",
    "        print(f'■■ base_i={base_i}/{n_base} (si={si}, ri={ri}/{num_repeats})')\n",
    "\n",
    "        classifier = nn.Linear(num_features, len(label_list)).to(device) \n",
    "        classifier.weight.data = torch.from_numpy(dense_wbs_set[base_i][0]).to(device)\n",
    "        classifier.bias.data = torch.from_numpy(dense_wbs_set[base_i][1]).to(device)\n",
    "        optimizer = torch.optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=lr)\n",
    "\n",
    "        num_patience = 0\n",
    "        max_val_loss = np.inf\n",
    "        for epoch in range(1,epochs+1):\n",
    "            batch_indices = np.random.permutation(trn_len)\n",
    "            for ti in range(trn_len//btchs):\n",
    "                bat_indices = batch_indices[ti*btchs:(ti+1)*btchs]\n",
    "                X_bat, y_bat = fs.arrow2batch(trn_arrow, bat_indices, tokenizer, max_length, device)\n",
    "\n",
    "                model.train()\n",
    "                bat_vectors = model(**X_bat).pooler_output # For 'distilbert', you may use 'model(**X_bat)['last_hidden_state'][:,0,:]'\n",
    "                bat_logits = classifier(model_dropout(bat_vectors))\n",
    "                bat_loss = cross_entropy(bat_logits, y_bat)\n",
    "                model.zero_grad()\n",
    "                bat_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            suffix = ''\n",
    "            val_acc, val_loss = fs.eval_accuracy(dev_arrow, 2*btchs, model, tokenizer, max_length, classifier, device)\n",
    "            if best_val_loss>val_loss:\n",
    "                best_val_loss=val_loss\n",
    "                suffix = ' #'\n",
    "                \n",
    "                model_ri = OrderedDict({key:val.to('cpu') for key,val in model.state_dict().items()})\n",
    "                dense_ri = OrderedDict({key:val.to('cpu') for key,val in classifier.state_dict().items()})\n",
    "\n",
    "            if max_val_loss > val_loss:\n",
    "                max_val_loss = val_loss\n",
    "                num_patience = 0\n",
    "            else:\n",
    "                num_patience += 1\n",
    "            \n",
    "            if num_patience > 10:\n",
    "                break\n",
    "            \n",
    "            print(f'■■■ epoch={epoch}, val_acc={round(val_acc,4)}, val_loss={round(val_loss,4)} {suffix}')\n",
    "\n",
    "    torch.save(model_ri, f'./params/wa_param_backbone_{ri}.pt')\n",
    "    torch.save(dense_ri, f'./params/wa_param_dense_{ri}.pt')\n",
    "    print(f'■ Saved the parameters at {time.ctime()}.')\n",
    "\n",
    "print(50*'#')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fde9cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WA-init algorithm: Phase-2 model initialization\n"
     ]
    }
   ],
   "source": [
    "print('WA-init algorithm: Phase-2 model initialization')\n",
    "##################################################\n",
    "alpha = 0.334\n",
    "use_wa_init = True # if use_wa_init=False, it does not use WA-init.\n",
    "model_dropout = nn.Dropout(dr).to(device)\n",
    "##################################################\n",
    "\n",
    "'Load the previously calculated stop-criterion.'\n",
    "dev_stop_epochs, ref_confs = fs.load_all(f'./params/stop_infs_si{si}.bin')\n",
    "\n",
    "'Model initialization'\n",
    "model.init_weights()\n",
    "classifier = nn.Linear(num_features, len(label_list)).to(device)\n",
    "\n",
    "model_o = init_state_dict\n",
    "dense_o = nn.Linear(num_features, len(label_list)).state_dict() \n",
    "\n",
    "if use_wa_init:\n",
    "    'init with good parameters'\n",
    "    new_params_m = OrderedDict()\n",
    "    for key in model_o.keys():\n",
    "        new_params_m[key] = alpha * model_o[key]\n",
    "    for ri in range(num_repeats):\n",
    "        model_ri = torch.load(f'./params/wa_param_backbone_{ri}.pt')\n",
    "        for key in model_o.keys():\n",
    "            new_params_m[key] += ((1.-alpha)/num_repeats) * model_ri[key]\n",
    "\n",
    "    new_params_d = OrderedDict()\n",
    "    for key in dense_o.keys():\n",
    "        new_params_d[key] = alpha * dense_o[key]\n",
    "    for ri in range(num_repeats):\n",
    "        dense_ri = torch.load(f'./params/wa_param_dense_{ri}.pt')\n",
    "        for key in dense_o.keys():\n",
    "            new_params_d[key] += ((1.-alpha)/num_repeats) * dense_ri[key]\n",
    "\n",
    "    model.load_state_dict( new_params_m )\n",
    "    classifier.load_state_dict( new_params_d )\n",
    "else:\n",
    "    'init with original parameters'\n",
    "    model.load_state_dict( model_o )\n",
    "    classifier.load_state_dict( dense_o )\n",
    "optimizer = torch.optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660cfc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WA-init algorithm: Phase-2 all sample training\n",
      "use_wa_init=True\n",
      "■ epoch=1, trn_acc=0.9613, es_cf=2.65 #\n",
      "■ epoch=2, trn_acc=1.0, es_cf=1.5698 #\n",
      "■ epoch=3, trn_acc=1.0, es_cf=0.8988 #\n",
      "■ epoch=4, trn_acc=1.0, es_cf=0.3412 #\n",
      "■ epoch=5, trn_acc=1.0, es_cf=0.1096 #\n",
      "■ epoch=6, trn_acc=1.0, es_cf=0.2708 \n",
      "■ epoch=7, trn_acc=1.0, es_cf=0.4146 \n",
      "■ epoch=8, trn_acc=1.0, es_cf=0.4982 \n",
      "■ epoch=9, trn_acc=1.0, es_cf=0.5538 \n",
      "■ epoch=10, trn_acc=1.0, es_cf=0.5907 \n",
      "■ epoch=11, trn_acc=1.0, es_cf=0.6153 \n",
      "■ epoch=12, trn_acc=1.0, es_cf=0.6328 \n",
      "■ epoch=13, trn_acc=1.0, es_cf=0.6459 \n",
      "■ epoch=14, trn_acc=1.0, es_cf=0.6559 \n",
      "■ epoch=15, trn_acc=1.0, es_cf=0.6637 \n",
      "\n",
      "-- Final results --\n",
      "tst_acc,tst_loss,tst_ece,tst_oe = (0.8737, 0.3315, 0.044, 0.028)\n"
     ]
    }
   ],
   "source": [
    "print('WA-init algorithm: Phase-2 all sample training')\n",
    "##################################################\n",
    "print(f'use_wa_init={use_wa_init}')\n",
    "\n",
    "trn_examples, _, _ = fs.divide_samples(examples, si=si, use_rate=use_rate, trn_rate=1.0) \n",
    "trn_arrow = fs.example2arrow(trn_examples, label_map)\n",
    "tst_arrow = fs.example2arrow(tst_examples, label_map)\n",
    "trn_len,tst_len = len(trn_arrow),len(tst_arrow)\n",
    "\n",
    "max_crt = np.inf\n",
    "num_patience = 0\n",
    "for epoch in range(1,epochs+1):\n",
    "    batch_indices = np.random.permutation(trn_len)\n",
    "    for ti in range(trn_len//btchs):\n",
    "        bat_indices = batch_indices[ti*btchs:(ti+1)*btchs]\n",
    "        X_bat, y_bat = fs.arrow2batch(trn_arrow, bat_indices, tokenizer, max_length, device)\n",
    "\n",
    "        model.train()\n",
    "        bat_vectors = model(**X_bat).pooler_output\n",
    "        bat_logits = classifier(model_dropout(bat_vectors))\n",
    "        bat_loss = cross_entropy(bat_logits, y_bat)\n",
    "        model.zero_grad()\n",
    "        bat_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    suffix = ''\n",
    "    trn_golds, trn_probs = fs.eval_accuracy(trn_arrow, 2*btchs, model, tokenizer, max_length, classifier, device, True)\n",
    "    trn_acc = accuracy_score(trn_golds, trn_probs.argmax(1))\n",
    "    es_cf = np.linalg.norm(np.sort(trn_probs.max(1))-ref_confs)\n",
    "\n",
    "    if max_crt > es_cf:\n",
    "        max_crt = es_cf\n",
    "        num_patience = 0\n",
    "        suffix = '#'\n",
    "        model_best = OrderedDict({key:val.to('cpu') for key,val in model.state_dict().items()})\n",
    "        dense_best = OrderedDict({key:val.to('cpu') for key,val in classifier.state_dict().items()})\n",
    "    else:\n",
    "        num_patience += 1\n",
    "    \n",
    "    if num_patience > 10:\n",
    "        break\n",
    "\n",
    "    print(f'■ epoch={epoch}, trn_acc={round(trn_acc,4)}, es_cf={round(es_cf,4)} {suffix}')\n",
    "\n",
    "model.load_state_dict(model_best)\n",
    "classifier.load_state_dict(dense_best)\n",
    "tst_golds,tst_probs = fs.eval_accuracy(tst_arrow, 2*btchs, model, tokenizer, max_length, classifier, device, True)\n",
    "tst_acc,tst_loss,tst_ece,tst_oe = fs.eval_metrics(tst_golds,tst_probs,bins=15)\n",
    "\n",
    "print('\\n-- Final results --')\n",
    "print(f'tst_acc,tst_loss,tst_ece,tst_oe = {tuple( np.around([tst_acc,tst_loss,tst_ece,tst_oe],4) )}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0df06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325d799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd232dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e23ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2f973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0e3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237ca75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f07029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb2b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a6e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b94b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b33a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berts",
   "language": "python",
   "name": "berts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
